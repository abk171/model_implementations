{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba859e9-7c02-4378-8b1a-45f54aabe988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40d2c5d2-90d6-46e1-b476-f282d03f15b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbeddings(nn.Module):\n",
    "    def __init__(self, in_channels=3, patch_size=16, embedding_dimension=12):\n",
    "        super(PatchEmbeddings, self).__init__()\n",
    "        self.in_channels= in_channels\n",
    "        self.patch_size= patch_size\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "\n",
    "        self.patch = nn.Conv2d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.embedding_dimension,\n",
    "            kernel_size=self.patch_size,\n",
    "            stride=self.patch_size,\n",
    "            padding=0,\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch(x)\n",
    "        x = x.flatten(2).transpose(1,2)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41e9dab6-e601-4ced-bcca-47d629fb4930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 12, 14, 14]           9,228\n",
      "================================================================\n",
      "Total params: 9,228\n",
      "Trainable params: 9,228\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "embedding = PatchEmbeddings()\n",
    "summary(embedding, (3,224,224), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d26dabbd-184a-456f-b879-9c44bf6d9fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 196, 12])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3,3,224,224)\n",
    "embedding(x).shape\n",
    "## this is of the form (Batch, num_patches, embdedding_dimension)\n",
    "## can be calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e65078b-384c-4661-8075-cfad04d97c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embedding_dimension=12, num_heads=6, mlp_dimension=256, dropout=0.1, **kwargs):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        self.msa_norm = nn.LayerNorm(embedding_dimension)\n",
    "        self.msa = nn.MultiheadAttention(\n",
    "            embed_dim=embedding_dimension,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.mlp_norm = nn.LayerNorm(embedding_dimension)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embedding_dimension, mlp_dimension),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_dimension, embedding_dimension)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.msa_norm(x)\n",
    "        msa_res = x\n",
    "        x,_ = self.msa(x,x,x)\n",
    "        x = msa_res + F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.mlp_norm(x)\n",
    "        mlp_res = x        \n",
    "        x = self.mlp(x)\n",
    "        x = mlp_res + F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "886bc920-45fd-4ddb-804c-36147f0a3154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         LayerNorm-1              [-1, 197, 12]              24\n",
      "MultiheadAttention-2  [[-1, 197, 12], [-1, 197, 197]]               0\n",
      "         LayerNorm-3              [-1, 197, 12]              24\n",
      "            Linear-4             [-1, 197, 256]           3,328\n",
      "              GELU-5             [-1, 197, 256]               0\n",
      "           Dropout-6             [-1, 197, 256]               0\n",
      "            Linear-7              [-1, 197, 12]           3,084\n",
      "================================================================\n",
      "Total params: 6,460\n",
      "Trainable params: 6,460\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 698.75\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 698.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "block = TransformerBlock()\n",
    "summary(block, (197,12), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34ac47d3-3604-4d70-8d97-6459e48422b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 196, 12])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3,196,12)\n",
    "block(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60916a67-6a9d-4c8b-8e0c-5eb978e104b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers=8, embedding_dimension=12, **kwargs):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList([TransformerBlock(embedding_dimension, **kwargs) for _ in range(num_layers)])\n",
    "        \n",
    "        self.final_norm = nn.LayerNorm(embedding_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)  \n",
    "        x = self.final_norm(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "664c1a9e-ddbf-49e2-b56f-70bfff0e1793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         LayerNorm-1              [-1, 197, 12]              24\n",
      "MultiheadAttention-2  [[-1, 197, 12], [-1, 197, 197]]               0\n",
      "         LayerNorm-3              [-1, 197, 12]              24\n",
      "            Linear-4             [-1, 197, 256]           3,328\n",
      "              GELU-5             [-1, 197, 256]               0\n",
      "           Dropout-6             [-1, 197, 256]               0\n",
      "            Linear-7              [-1, 197, 12]           3,084\n",
      "  TransformerBlock-8              [-1, 197, 12]               0\n",
      "         LayerNorm-9              [-1, 197, 12]              24\n",
      "MultiheadAttention-10  [[-1, 197, 12], [-1, 197, 197]]               0\n",
      "        LayerNorm-11              [-1, 197, 12]              24\n",
      "           Linear-12             [-1, 197, 256]           3,328\n",
      "             GELU-13             [-1, 197, 256]               0\n",
      "          Dropout-14             [-1, 197, 256]               0\n",
      "           Linear-15              [-1, 197, 12]           3,084\n",
      " TransformerBlock-16              [-1, 197, 12]               0\n",
      "        LayerNorm-17              [-1, 197, 12]              24\n",
      "MultiheadAttention-18  [[-1, 197, 12], [-1, 197, 197]]               0\n",
      "        LayerNorm-19              [-1, 197, 12]              24\n",
      "           Linear-20             [-1, 197, 256]           3,328\n",
      "             GELU-21             [-1, 197, 256]               0\n",
      "          Dropout-22             [-1, 197, 256]               0\n",
      "           Linear-23              [-1, 197, 12]           3,084\n",
      " TransformerBlock-24              [-1, 197, 12]               0\n",
      "        LayerNorm-25              [-1, 197, 12]              24\n",
      "MultiheadAttention-26  [[-1, 197, 12], [-1, 197, 197]]               0\n",
      "        LayerNorm-27              [-1, 197, 12]              24\n",
      "           Linear-28             [-1, 197, 256]           3,328\n",
      "             GELU-29             [-1, 197, 256]               0\n",
      "          Dropout-30             [-1, 197, 256]               0\n",
      "           Linear-31              [-1, 197, 12]           3,084\n",
      " TransformerBlock-32              [-1, 197, 12]               0\n",
      "        LayerNorm-33              [-1, 197, 12]              24\n",
      "MultiheadAttention-34  [[-1, 197, 12], [-1, 197, 197]]               0\n",
      "        LayerNorm-35              [-1, 197, 12]              24\n",
      "           Linear-36             [-1, 197, 256]           3,328\n",
      "             GELU-37             [-1, 197, 256]               0\n",
      "          Dropout-38             [-1, 197, 256]               0\n",
      "           Linear-39              [-1, 197, 12]           3,084\n",
      " TransformerBlock-40              [-1, 197, 12]               0\n",
      "        LayerNorm-41              [-1, 197, 12]              24\n",
      "MultiheadAttention-42  [[-1, 197, 12], [-1, 197, 197]]               0\n",
      "        LayerNorm-43              [-1, 197, 12]              24\n",
      "           Linear-44             [-1, 197, 256]           3,328\n",
      "             GELU-45             [-1, 197, 256]               0\n",
      "          Dropout-46             [-1, 197, 256]               0\n",
      "           Linear-47              [-1, 197, 12]           3,084\n",
      " TransformerBlock-48              [-1, 197, 12]               0\n",
      "        LayerNorm-49              [-1, 197, 12]              24\n",
      "MultiheadAttention-50  [[-1, 197, 12], [-1, 197, 197]]               0\n",
      "        LayerNorm-51              [-1, 197, 12]              24\n",
      "           Linear-52             [-1, 197, 256]           3,328\n",
      "             GELU-53             [-1, 197, 256]               0\n",
      "          Dropout-54             [-1, 197, 256]               0\n",
      "           Linear-55              [-1, 197, 12]           3,084\n",
      " TransformerBlock-56              [-1, 197, 12]               0\n",
      "        LayerNorm-57              [-1, 197, 12]              24\n",
      "MultiheadAttention-58  [[-1, 197, 12], [-1, 197, 197]]               0\n",
      "        LayerNorm-59              [-1, 197, 12]              24\n",
      "           Linear-60             [-1, 197, 256]           3,328\n",
      "             GELU-61             [-1, 197, 256]               0\n",
      "          Dropout-62             [-1, 197, 256]               0\n",
      "           Linear-63              [-1, 197, 12]           3,084\n",
      " TransformerBlock-64              [-1, 197, 12]               0\n",
      "        LayerNorm-65              [-1, 197, 12]              24\n",
      "================================================================\n",
      "Total params: 51,704\n",
      "Trainable params: 51,704\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5589.81\n",
      "Params size (MB): 0.20\n",
      "Estimated Total Size (MB): 5590.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder()\n",
    "summary(encoder, (197,12), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b5ec15f-3d47-4192-845b-ed066a6b9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, img_size=224, hidden_dim=1024, num_classes=1000, \n",
    "                 num_layers=8, embedding_dim=768,\n",
    "                 in_channels=3, patch_size=16,\n",
    "                 **kwargs):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "\n",
    "        self.patch_embed = PatchEmbeddings(in_channels, patch_size, embedding_dim)\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embedding_dim))\n",
    "        \n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, self.num_patches + 1, embedding_dim))  \n",
    "\n",
    "        self.transformer = Encoder(num_layers,embedding_dim, **kwargs)\n",
    "\n",
    "        ## From the paper, it is mentioned for pre-training, we need an MLP with a hidden layer\n",
    "        ## For finetuning, we use a single linear layer\n",
    "        \n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim), \n",
    "            nn.GELU(),  \n",
    "            nn.Linear(hidden_dim, num_classes)  \n",
    "        )\n",
    "\n",
    "        # self.mlp_head = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "\n",
    "        x = self.patch_embed(x)  # (B, num_patches, D)\n",
    "\n",
    "        ## -1 means no change along that dimension\n",
    "        cls_token = self.cls_token.expand(B, -1, -1)  # (B, 1, D)\n",
    "        x = torch.cat((cls_token, x), dim=1)  # (B, num_patches+1, D)\n",
    "\n",
    "        x = x + self.pos_embedding[:, :x.shape[1], :]\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # Use only CLS token for final classification\n",
    "        x = x[:, 0]  # (B, D)\n",
    "        return self.mlp_head(x)  # (B, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d75b0e30-d00c-4c64-adc1-dd751f62204f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 768, 14, 14]         590,592\n",
      "   PatchEmbeddings-2             [-1, 196, 768]               0\n",
      "         LayerNorm-3             [-1, 197, 768]           1,536\n",
      "MultiheadAttention-4  [[-1, 197, 768], [-1, 197, 197]]               0\n",
      "         LayerNorm-5             [-1, 197, 768]           1,536\n",
      "            Linear-6             [-1, 197, 256]         196,864\n",
      "              GELU-7             [-1, 197, 256]               0\n",
      "           Dropout-8             [-1, 197, 256]               0\n",
      "            Linear-9             [-1, 197, 768]         197,376\n",
      " TransformerBlock-10             [-1, 197, 768]               0\n",
      "        LayerNorm-11             [-1, 197, 768]           1,536\n",
      "MultiheadAttention-12  [[-1, 197, 768], [-1, 197, 197]]               0\n",
      "        LayerNorm-13             [-1, 197, 768]           1,536\n",
      "           Linear-14             [-1, 197, 256]         196,864\n",
      "             GELU-15             [-1, 197, 256]               0\n",
      "          Dropout-16             [-1, 197, 256]               0\n",
      "           Linear-17             [-1, 197, 768]         197,376\n",
      " TransformerBlock-18             [-1, 197, 768]               0\n",
      "        LayerNorm-19             [-1, 197, 768]           1,536\n",
      "MultiheadAttention-20  [[-1, 197, 768], [-1, 197, 197]]               0\n",
      "        LayerNorm-21             [-1, 197, 768]           1,536\n",
      "           Linear-22             [-1, 197, 256]         196,864\n",
      "             GELU-23             [-1, 197, 256]               0\n",
      "          Dropout-24             [-1, 197, 256]               0\n",
      "           Linear-25             [-1, 197, 768]         197,376\n",
      " TransformerBlock-26             [-1, 197, 768]               0\n",
      "        LayerNorm-27             [-1, 197, 768]           1,536\n",
      "MultiheadAttention-28  [[-1, 197, 768], [-1, 197, 197]]               0\n",
      "        LayerNorm-29             [-1, 197, 768]           1,536\n",
      "           Linear-30             [-1, 197, 256]         196,864\n",
      "             GELU-31             [-1, 197, 256]               0\n",
      "          Dropout-32             [-1, 197, 256]               0\n",
      "           Linear-33             [-1, 197, 768]         197,376\n",
      " TransformerBlock-34             [-1, 197, 768]               0\n",
      "        LayerNorm-35             [-1, 197, 768]           1,536\n",
      "MultiheadAttention-36  [[-1, 197, 768], [-1, 197, 197]]               0\n",
      "        LayerNorm-37             [-1, 197, 768]           1,536\n",
      "           Linear-38             [-1, 197, 256]         196,864\n",
      "             GELU-39             [-1, 197, 256]               0\n",
      "          Dropout-40             [-1, 197, 256]               0\n",
      "           Linear-41             [-1, 197, 768]         197,376\n",
      " TransformerBlock-42             [-1, 197, 768]               0\n",
      "        LayerNorm-43             [-1, 197, 768]           1,536\n",
      "MultiheadAttention-44  [[-1, 197, 768], [-1, 197, 197]]               0\n",
      "        LayerNorm-45             [-1, 197, 768]           1,536\n",
      "           Linear-46             [-1, 197, 256]         196,864\n",
      "             GELU-47             [-1, 197, 256]               0\n",
      "          Dropout-48             [-1, 197, 256]               0\n",
      "           Linear-49             [-1, 197, 768]         197,376\n",
      " TransformerBlock-50             [-1, 197, 768]               0\n",
      "        LayerNorm-51             [-1, 197, 768]           1,536\n",
      "MultiheadAttention-52  [[-1, 197, 768], [-1, 197, 197]]               0\n",
      "        LayerNorm-53             [-1, 197, 768]           1,536\n",
      "           Linear-54             [-1, 197, 256]         196,864\n",
      "             GELU-55             [-1, 197, 256]               0\n",
      "          Dropout-56             [-1, 197, 256]               0\n",
      "           Linear-57             [-1, 197, 768]         197,376\n",
      " TransformerBlock-58             [-1, 197, 768]               0\n",
      "        LayerNorm-59             [-1, 197, 768]           1,536\n",
      "MultiheadAttention-60  [[-1, 197, 768], [-1, 197, 197]]               0\n",
      "        LayerNorm-61             [-1, 197, 768]           1,536\n",
      "           Linear-62             [-1, 197, 256]         196,864\n",
      "             GELU-63             [-1, 197, 256]               0\n",
      "          Dropout-64             [-1, 197, 256]               0\n",
      "           Linear-65             [-1, 197, 768]         197,376\n",
      " TransformerBlock-66             [-1, 197, 768]               0\n",
      "        LayerNorm-67             [-1, 197, 768]           1,536\n",
      "          Encoder-68             [-1, 197, 768]               0\n",
      "           Linear-69                 [-1, 1024]         787,456\n",
      "             GELU-70                 [-1, 1024]               0\n",
      "           Linear-71                 [-1, 1000]       1,025,000\n",
      "================================================================\n",
      "Total params: 5,583,080\n",
      "Trainable params: 5,583,080\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 358326.06\n",
      "Params size (MB): 21.30\n",
      "Estimated Total Size (MB): 358347.93\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = VisionTransformer()\n",
    "summary(model, (3,224,224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9d6c801-0d79-4bfc-8657-12af6129cdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(2, 3, 224, 224)  \n",
    "output = model(x)\n",
    "print(output.shape)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
