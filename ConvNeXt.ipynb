{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ade211c3-c527-43bc-8e4d-dda0562d9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daaae54d-f690-48a0-85f0-adf949bbd155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXtBlock2D(nn.Module):\n",
    "  def __init__(self, dim, layer_scale_init_value=1e-6, drop=0.2):\n",
    "    super().__init__()\n",
    "\n",
    "    self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)  # depthwise conv\n",
    "\n",
    "    self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    self.pwconv1 = nn.Linear(dim, 4 * dim)\n",
    "    self.act = nn.GELU()\n",
    "    self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "\n",
    "    self.dropout = nn.Dropout2d(p=drop)\n",
    "\n",
    "    self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim,)), requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    residual = x\n",
    "    x = self.dwconv(x)\n",
    "\n",
    "    # Transpose for LayerNorm\n",
    "    x = x.permute(0, 2, 3, 1)\n",
    "    x = self.norm(x)\n",
    "\n",
    "    x = self.pwconv1(x)\n",
    "    x = self.act(x)\n",
    "    x = self.pwconv2(x)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    if self.gamma is not None:\n",
    "        x = self.gamma * x\n",
    "\n",
    "    # Transpose back to (B, C, H, W)\n",
    "    x = x.permute(0, 3, 1, 2)\n",
    "    # no drop path y\n",
    "    return residual + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bc73932-0356-4583-95e4-45c5bf5fcca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 224, 224]           4,800\n",
      "         LayerNorm-2         [-1, 224, 224, 96]             192\n",
      "            Linear-3        [-1, 224, 224, 384]          37,248\n",
      "              GELU-4        [-1, 224, 224, 384]               0\n",
      "            Linear-5         [-1, 224, 224, 96]          36,960\n",
      "         Dropout2d-6         [-1, 224, 224, 96]               0\n",
      "================================================================\n",
      "Total params: 79,200\n",
      "Trainable params: 79,200\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 18.38\n",
      "Forward/backward pass size (MB): 441.00\n",
      "Params size (MB): 0.30\n",
      "Estimated Total Size (MB): 459.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(ConvNeXtBlock2D(96), (96,224,224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ce696a-b108-4ffd-88d6-47598d8d1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNext(nn.Module):\n",
    "    def __init__(self, in_chans=1, dims=[32, 64, 128, 256], stages=[1, 1, 3, 1]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.dims = dims\n",
    "        self.stages = stages\n",
    "\n",
    "        self.downsample_layers = nn.ModuleList()  # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            myLayerNorm(dims[0], eps=1e-6)\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                myLayerNorm(dims[i], eps=1e-6),\n",
    "                nn.Conv2d(dims[i], dims[i + 1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.model_layers = nn.ModuleList()\n",
    "        for i, stage_length in enumerate(stages):\n",
    "            stage = nn.ModuleList([ConvNeXtBlock2D(dims[i]) for _ in range(stage_length)])\n",
    "            self.model_layers.append(stage)\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.final_norm = nn.LayerNorm(dims[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.dims)):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            for layer in self.model_layers[i]:\n",
    "                x = layer(x)\n",
    "\n",
    "        x = self.pooling(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.final_norm(x)  # Final normalization\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd4505f7-9f85-4860-8170-570144c8ce9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'myLayerNorm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m summary(\u001b[43mConvNext\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_chans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m, in \u001b[0;36mConvNext.__init__\u001b[0;34m(self, in_chans, dims, stages)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages \u001b[38;5;241m=\u001b[39m stages\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample_layers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList()  \u001b[38;5;66;03m# stem and 3 intermediate downsampling conv layers\u001b[39;00m\n\u001b[1;32m     10\u001b[0m stem \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     11\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(in_chans, dims[\u001b[38;5;241m0\u001b[39m], kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mmyLayerNorm\u001b[49m(dims[\u001b[38;5;241m0\u001b[39m], eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample_layers\u001b[38;5;241m.\u001b[39mappend(stem)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'myLayerNorm' is not defined"
     ]
    }
   ],
   "source": [
    "summary(ConvNext(in_chans=3,dims=[96,192,384,768],stages=[3,3,9,3]), (3,224,224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58c570-aaf7-410d-a073-eb1d5bd85507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
