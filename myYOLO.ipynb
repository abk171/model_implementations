{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2060fe75-35c8-4d72-add5-7637fee999ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f9184-b880-4c83-bb31-a75e8796ee16",
   "metadata": {},
   "source": [
    "## Dynamic Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd8ba601-143d-4ff5-97c5-7f9560c926ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DyT(nn.Module):\n",
    "    def __init__(self, dims, init_alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.ones(1)) * init_alpha\n",
    "        self.gamma = nn.Parameter(torch.ones(dims))\n",
    "        self.beta = nn.Parameter(torch.zeros(dims))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gamma * torch.tanh(self.alpha * x) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "315f18cc-6189-445e-9323-dab6022ab684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DyT_wrapper(nn.Module):\n",
    "    def __init__(self, dims, init_alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.dyt = DyT(dims, init_alpha)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.movedim(x, 1,-1)\n",
    "        x = self.dyt(x)\n",
    "        x = torch.movedim(x, -1, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed157e6-c520-4cd5-a135-51c55ee4bc26",
   "metadata": {},
   "source": [
    "## ConvNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb2ac4b4-5355-4fc1-8c63-7f2596df8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXtBlock2D(nn.Module):\n",
    "  def __init__(self, dim, layer_scale_init_value=1e-6, drop=0.2):\n",
    "    super().__init__()\n",
    "\n",
    "    self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)  # depthwise conv\n",
    "\n",
    "    # self.norm = nn.LayerNorm(dim)\n",
    "    self.norm = DyT(dim)\n",
    "\n",
    "    self.pwconv1 = nn.Linear(dim, 4 * dim)\n",
    "    self.act = nn.GELU()\n",
    "    self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "\n",
    "    self.dropout = nn.Dropout2d(p=drop)\n",
    "\n",
    "    self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim,)), requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    residual = x\n",
    "    x = self.dwconv(x)\n",
    "\n",
    "    # Transpose for LayerNorm\n",
    "    x = x.permute(0, 2, 3, 1)\n",
    "    x = self.norm(x)\n",
    "\n",
    "    x = self.pwconv1(x)\n",
    "    x = self.act(x)\n",
    "    x = self.pwconv2(x)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    if self.gamma is not None:\n",
    "        x = self.gamma * x\n",
    "\n",
    "    # Transpose back to (B, C, H, W)\n",
    "    x = x.permute(0, 3, 1, 2)\n",
    "    # no drop path y\n",
    "    return residual + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2365b568-9d03-486d-8ed0-1861e24e1380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 112, 112]           4,800\n",
      "               DyT-2         [-1, 112, 112, 96]               0\n",
      "            Linear-3        [-1, 112, 112, 384]          37,248\n",
      "              GELU-4        [-1, 112, 112, 384]               0\n",
      "            Linear-5         [-1, 112, 112, 96]          36,960\n",
      "         Dropout2d-6         [-1, 112, 112, 96]               0\n",
      "================================================================\n",
      "Total params: 79,008\n",
      "Trainable params: 79,008\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.59\n",
      "Forward/backward pass size (MB): 110.25\n",
      "Params size (MB): 0.30\n",
      "Estimated Total Size (MB): 115.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "block = ConvNeXtBlock2D(96)\n",
    "summary(block, (96,112,112), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b224cc37-6061-4473-acf4-46c742937b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNext(nn.Module):\n",
    "    def __init__(self, in_chans=1, dims=[32, 64, 128, 256], stages=[1, 1, 3, 1]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.dims = dims\n",
    "        self.stages = stages\n",
    "\n",
    "        self.downsample_layers = nn.ModuleList()  # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            # myLayerNorm(dims[0], eps=1e-6)\n",
    "            DyT_wrapper(dims[0])\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                # myLayerNorm(dims[i], eps=1e-6),\n",
    "                DyT_wrapper(dims[i]),\n",
    "                nn.Conv2d(dims[i], dims[i + 1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.model_layers = nn.ModuleList()\n",
    "        for i, stage_length in enumerate(stages):\n",
    "            stage = nn.ModuleList([ConvNeXtBlock2D(dims[i]) for _ in range(stage_length)])\n",
    "            self.model_layers.append(stage)\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        # self.final_norm = nn.LayerNorm(dims[-1])\n",
    "        self.final_norm = DyT_wrapper(dims[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.dims)):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            for layer in self.model_layers[i]:\n",
    "                x = layer(x)\n",
    "\n",
    "        x = self.pooling(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.final_norm(x)  # Final normalization\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25e81761-8eb8-411e-8ce4-54fe4abeea0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 56, 56]           4,704\n",
      "               DyT-2           [-1, 56, 56, 96]               0\n",
      "       DyT_wrapper-3           [-1, 96, 56, 56]               0\n",
      "            Conv2d-4           [-1, 96, 56, 56]           4,800\n",
      "               DyT-5           [-1, 56, 56, 96]               0\n",
      "            Linear-6          [-1, 56, 56, 384]          37,248\n",
      "              GELU-7          [-1, 56, 56, 384]               0\n",
      "            Linear-8           [-1, 56, 56, 96]          36,960\n",
      "         Dropout2d-9           [-1, 56, 56, 96]               0\n",
      "  ConvNeXtBlock2D-10           [-1, 96, 56, 56]               0\n",
      "           Conv2d-11           [-1, 96, 56, 56]           4,800\n",
      "              DyT-12           [-1, 56, 56, 96]               0\n",
      "           Linear-13          [-1, 56, 56, 384]          37,248\n",
      "             GELU-14          [-1, 56, 56, 384]               0\n",
      "           Linear-15           [-1, 56, 56, 96]          36,960\n",
      "        Dropout2d-16           [-1, 56, 56, 96]               0\n",
      "  ConvNeXtBlock2D-17           [-1, 96, 56, 56]               0\n",
      "           Conv2d-18           [-1, 96, 56, 56]           4,800\n",
      "              DyT-19           [-1, 56, 56, 96]               0\n",
      "           Linear-20          [-1, 56, 56, 384]          37,248\n",
      "             GELU-21          [-1, 56, 56, 384]               0\n",
      "           Linear-22           [-1, 56, 56, 96]          36,960\n",
      "        Dropout2d-23           [-1, 56, 56, 96]               0\n",
      "  ConvNeXtBlock2D-24           [-1, 96, 56, 56]               0\n",
      "              DyT-25           [-1, 56, 56, 96]               0\n",
      "      DyT_wrapper-26           [-1, 96, 56, 56]               0\n",
      "           Conv2d-27          [-1, 192, 28, 28]          73,920\n",
      "           Conv2d-28          [-1, 192, 28, 28]           9,600\n",
      "              DyT-29          [-1, 28, 28, 192]               0\n",
      "           Linear-30          [-1, 28, 28, 768]         148,224\n",
      "             GELU-31          [-1, 28, 28, 768]               0\n",
      "           Linear-32          [-1, 28, 28, 192]         147,648\n",
      "        Dropout2d-33          [-1, 28, 28, 192]               0\n",
      "  ConvNeXtBlock2D-34          [-1, 192, 28, 28]               0\n",
      "           Conv2d-35          [-1, 192, 28, 28]           9,600\n",
      "              DyT-36          [-1, 28, 28, 192]               0\n",
      "           Linear-37          [-1, 28, 28, 768]         148,224\n",
      "             GELU-38          [-1, 28, 28, 768]               0\n",
      "           Linear-39          [-1, 28, 28, 192]         147,648\n",
      "        Dropout2d-40          [-1, 28, 28, 192]               0\n",
      "  ConvNeXtBlock2D-41          [-1, 192, 28, 28]               0\n",
      "           Conv2d-42          [-1, 192, 28, 28]           9,600\n",
      "              DyT-43          [-1, 28, 28, 192]               0\n",
      "           Linear-44          [-1, 28, 28, 768]         148,224\n",
      "             GELU-45          [-1, 28, 28, 768]               0\n",
      "           Linear-46          [-1, 28, 28, 192]         147,648\n",
      "        Dropout2d-47          [-1, 28, 28, 192]               0\n",
      "  ConvNeXtBlock2D-48          [-1, 192, 28, 28]               0\n",
      "              DyT-49          [-1, 28, 28, 192]               0\n",
      "      DyT_wrapper-50          [-1, 192, 28, 28]               0\n",
      "           Conv2d-51          [-1, 384, 14, 14]         295,296\n",
      "           Conv2d-52          [-1, 384, 14, 14]          19,200\n",
      "              DyT-53          [-1, 14, 14, 384]               0\n",
      "           Linear-54         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-55         [-1, 14, 14, 1536]               0\n",
      "           Linear-56          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-57          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-58          [-1, 384, 14, 14]               0\n",
      "           Conv2d-59          [-1, 384, 14, 14]          19,200\n",
      "              DyT-60          [-1, 14, 14, 384]               0\n",
      "           Linear-61         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-62         [-1, 14, 14, 1536]               0\n",
      "           Linear-63          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-64          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-65          [-1, 384, 14, 14]               0\n",
      "           Conv2d-66          [-1, 384, 14, 14]          19,200\n",
      "              DyT-67          [-1, 14, 14, 384]               0\n",
      "           Linear-68         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-69         [-1, 14, 14, 1536]               0\n",
      "           Linear-70          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-71          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-72          [-1, 384, 14, 14]               0\n",
      "           Conv2d-73          [-1, 384, 14, 14]          19,200\n",
      "              DyT-74          [-1, 14, 14, 384]               0\n",
      "           Linear-75         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-76         [-1, 14, 14, 1536]               0\n",
      "           Linear-77          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-78          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-79          [-1, 384, 14, 14]               0\n",
      "           Conv2d-80          [-1, 384, 14, 14]          19,200\n",
      "              DyT-81          [-1, 14, 14, 384]               0\n",
      "           Linear-82         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-83         [-1, 14, 14, 1536]               0\n",
      "           Linear-84          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-85          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-86          [-1, 384, 14, 14]               0\n",
      "           Conv2d-87          [-1, 384, 14, 14]          19,200\n",
      "              DyT-88          [-1, 14, 14, 384]               0\n",
      "           Linear-89         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-90         [-1, 14, 14, 1536]               0\n",
      "           Linear-91          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-92          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-93          [-1, 384, 14, 14]               0\n",
      "           Conv2d-94          [-1, 384, 14, 14]          19,200\n",
      "              DyT-95          [-1, 14, 14, 384]               0\n",
      "           Linear-96         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-97         [-1, 14, 14, 1536]               0\n",
      "           Linear-98          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-99          [-1, 14, 14, 384]               0\n",
      " ConvNeXtBlock2D-100          [-1, 384, 14, 14]               0\n",
      "          Conv2d-101          [-1, 384, 14, 14]          19,200\n",
      "             DyT-102          [-1, 14, 14, 384]               0\n",
      "          Linear-103         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-104         [-1, 14, 14, 1536]               0\n",
      "          Linear-105          [-1, 14, 14, 384]         590,208\n",
      "       Dropout2d-106          [-1, 14, 14, 384]               0\n",
      " ConvNeXtBlock2D-107          [-1, 384, 14, 14]               0\n",
      "          Conv2d-108          [-1, 384, 14, 14]          19,200\n",
      "             DyT-109          [-1, 14, 14, 384]               0\n",
      "          Linear-110         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-111         [-1, 14, 14, 1536]               0\n",
      "          Linear-112          [-1, 14, 14, 384]         590,208\n",
      "       Dropout2d-113          [-1, 14, 14, 384]               0\n",
      " ConvNeXtBlock2D-114          [-1, 384, 14, 14]               0\n",
      "             DyT-115          [-1, 14, 14, 384]               0\n",
      "     DyT_wrapper-116          [-1, 384, 14, 14]               0\n",
      "          Conv2d-117            [-1, 768, 7, 7]       1,180,416\n",
      "          Conv2d-118            [-1, 768, 7, 7]          38,400\n",
      "             DyT-119            [-1, 7, 7, 768]               0\n",
      "          Linear-120           [-1, 7, 7, 3072]       2,362,368\n",
      "            GELU-121           [-1, 7, 7, 3072]               0\n",
      "          Linear-122            [-1, 7, 7, 768]       2,360,064\n",
      "       Dropout2d-123            [-1, 7, 7, 768]               0\n",
      " ConvNeXtBlock2D-124            [-1, 768, 7, 7]               0\n",
      "          Conv2d-125            [-1, 768, 7, 7]          38,400\n",
      "             DyT-126            [-1, 7, 7, 768]               0\n",
      "          Linear-127           [-1, 7, 7, 3072]       2,362,368\n",
      "            GELU-128           [-1, 7, 7, 3072]               0\n",
      "          Linear-129            [-1, 7, 7, 768]       2,360,064\n",
      "       Dropout2d-130            [-1, 7, 7, 768]               0\n",
      " ConvNeXtBlock2D-131            [-1, 768, 7, 7]               0\n",
      "          Conv2d-132            [-1, 768, 7, 7]          38,400\n",
      "             DyT-133            [-1, 7, 7, 768]               0\n",
      "          Linear-134           [-1, 7, 7, 3072]       2,362,368\n",
      "            GELU-135           [-1, 7, 7, 3072]               0\n",
      "          Linear-136            [-1, 7, 7, 768]       2,360,064\n",
      "       Dropout2d-137            [-1, 7, 7, 768]               0\n",
      " ConvNeXtBlock2D-138            [-1, 768, 7, 7]               0\n",
      "AdaptiveAvgPool2d-139            [-1, 768, 1, 1]               0\n",
      "         Flatten-140                  [-1, 768]               0\n",
      "             DyT-141                  [-1, 768]               0\n",
      "     DyT_wrapper-142                  [-1, 768]               0\n",
      "================================================================\n",
      "Total params: 27,797,184\n",
      "Trainable params: 27,797,184\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 229.71\n",
      "Params size (MB): 106.04\n",
      "Estimated Total Size (MB): 336.32\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(ConvNext(in_chans=3,dims=[96,192,384,768],stages=[3,3,9,3]), (3,224,224), device=\"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
