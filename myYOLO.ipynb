{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2060fe75-35c8-4d72-add5-7637fee999ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f9184-b880-4c83-bb31-a75e8796ee16",
   "metadata": {},
   "source": [
    "## Dynamic Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bd8ba601-143d-4ff5-97c5-7f9560c926ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DyT(nn.Module):\n",
    "    def __init__(self, dims, init_alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.ones(1) * init_alpha)\n",
    "        self.gamma = nn.Parameter(torch.ones(dims))\n",
    "        self.beta = nn.Parameter(torch.zeros(dims))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gamma * torch.tanh(self.alpha * x) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "315f18cc-6189-445e-9323-dab6022ab684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DyT_wrapper(nn.Module):\n",
    "    def __init__(self, dims, init_alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.dyt = DyT(dims, init_alpha)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.movedim(x, 1,-1)\n",
    "        x = self.dyt(x)\n",
    "        x = torch.movedim(x, -1, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed157e6-c520-4cd5-a135-51c55ee4bc26",
   "metadata": {},
   "source": [
    "## ConvNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fb2ac4b4-5355-4fc1-8c63-7f2596df8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXtBlock2D(nn.Module):\n",
    "  def __init__(self, dim, layer_scale_init_value=1e-6, drop=0.2, **kwargs):\n",
    "    super().__init__()\n",
    "\n",
    "    self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)  # depthwise conv\n",
    "\n",
    "    # self.norm = nn.LayerNorm(dim)\n",
    "    self.norm = DyT(dim)\n",
    "\n",
    "    self.pwconv1 = nn.Linear(dim, 4 * dim)\n",
    "    self.act = nn.GELU()\n",
    "    self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "\n",
    "    self.dropout = nn.Dropout2d(p=drop)\n",
    "\n",
    "    self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim,)), requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    residual = x\n",
    "    x = self.dwconv(x)\n",
    "\n",
    "    # Transpose for LayerNorm\n",
    "    x = x.permute(0, 2, 3, 1)\n",
    "    x = self.norm(x)\n",
    "\n",
    "    x = self.pwconv1(x)\n",
    "    x = self.act(x)\n",
    "    x = self.pwconv2(x)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    if self.gamma is not None:\n",
    "        x = self.gamma * x\n",
    "\n",
    "    # Transpose back to (B, C, H, W)\n",
    "    x = x.permute(0, 3, 1, 2)\n",
    "    # no drop path y\n",
    "    return residual + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2365b568-9d03-486d-8ed0-1861e24e1380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 112, 112]           4,800\n",
      "               DyT-2         [-1, 112, 112, 96]               0\n",
      "            Linear-3        [-1, 112, 112, 384]          37,248\n",
      "              GELU-4        [-1, 112, 112, 384]               0\n",
      "            Linear-5         [-1, 112, 112, 96]          36,960\n",
      "         Dropout2d-6         [-1, 112, 112, 96]               0\n",
      "================================================================\n",
      "Total params: 79,008\n",
      "Trainable params: 79,008\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.59\n",
      "Forward/backward pass size (MB): 110.25\n",
      "Params size (MB): 0.30\n",
      "Estimated Total Size (MB): 115.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "block = ConvNeXtBlock2D(96)\n",
    "summary(block, (96,112,112), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b224cc37-6061-4473-acf4-46c742937b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNext(nn.Module):\n",
    "    def __init__(self, in_chans=1, dims=[32, 64, 128, 256], stages=[1, 1, 3, 1]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.dims = dims\n",
    "        self.stages = stages\n",
    "\n",
    "        self.downsample_layers = nn.ModuleList()  # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            # myLayerNorm(dims[0], eps=1e-6)\n",
    "            DyT_wrapper(dims[0])\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                # myLayerNorm(dims[i], eps=1e-6),\n",
    "                DyT_wrapper(dims[i]),\n",
    "                nn.Conv2d(dims[i], dims[i + 1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.model_layers = nn.ModuleList()\n",
    "        for i, stage_length in enumerate(stages):\n",
    "            stage = nn.ModuleList([ConvNeXtBlock2D(dims[i]) for _ in range(stage_length)])\n",
    "            self.model_layers.append(stage)\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        # self.final_norm = nn.LayerNorm(dims[-1])\n",
    "        self.final_norm = DyT_wrapper(dims[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.dims)):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            for layer in self.model_layers[i]:\n",
    "                x = layer(x)\n",
    "\n",
    "        x = self.pooling(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.final_norm(x)  # Final normalization\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "25e81761-8eb8-411e-8ce4-54fe4abeea0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 56, 56]           4,704\n",
      "               DyT-2           [-1, 56, 56, 96]               0\n",
      "       DyT_wrapper-3           [-1, 96, 56, 56]               0\n",
      "            Conv2d-4           [-1, 96, 56, 56]           4,800\n",
      "               DyT-5           [-1, 56, 56, 96]               0\n",
      "            Linear-6          [-1, 56, 56, 384]          37,248\n",
      "              GELU-7          [-1, 56, 56, 384]               0\n",
      "            Linear-8           [-1, 56, 56, 96]          36,960\n",
      "         Dropout2d-9           [-1, 56, 56, 96]               0\n",
      "  ConvNeXtBlock2D-10           [-1, 96, 56, 56]               0\n",
      "           Conv2d-11           [-1, 96, 56, 56]           4,800\n",
      "              DyT-12           [-1, 56, 56, 96]               0\n",
      "           Linear-13          [-1, 56, 56, 384]          37,248\n",
      "             GELU-14          [-1, 56, 56, 384]               0\n",
      "           Linear-15           [-1, 56, 56, 96]          36,960\n",
      "        Dropout2d-16           [-1, 56, 56, 96]               0\n",
      "  ConvNeXtBlock2D-17           [-1, 96, 56, 56]               0\n",
      "           Conv2d-18           [-1, 96, 56, 56]           4,800\n",
      "              DyT-19           [-1, 56, 56, 96]               0\n",
      "           Linear-20          [-1, 56, 56, 384]          37,248\n",
      "             GELU-21          [-1, 56, 56, 384]               0\n",
      "           Linear-22           [-1, 56, 56, 96]          36,960\n",
      "        Dropout2d-23           [-1, 56, 56, 96]               0\n",
      "  ConvNeXtBlock2D-24           [-1, 96, 56, 56]               0\n",
      "              DyT-25           [-1, 56, 56, 96]               0\n",
      "      DyT_wrapper-26           [-1, 96, 56, 56]               0\n",
      "           Conv2d-27          [-1, 192, 28, 28]          73,920\n",
      "           Conv2d-28          [-1, 192, 28, 28]           9,600\n",
      "              DyT-29          [-1, 28, 28, 192]               0\n",
      "           Linear-30          [-1, 28, 28, 768]         148,224\n",
      "             GELU-31          [-1, 28, 28, 768]               0\n",
      "           Linear-32          [-1, 28, 28, 192]         147,648\n",
      "        Dropout2d-33          [-1, 28, 28, 192]               0\n",
      "  ConvNeXtBlock2D-34          [-1, 192, 28, 28]               0\n",
      "           Conv2d-35          [-1, 192, 28, 28]           9,600\n",
      "              DyT-36          [-1, 28, 28, 192]               0\n",
      "           Linear-37          [-1, 28, 28, 768]         148,224\n",
      "             GELU-38          [-1, 28, 28, 768]               0\n",
      "           Linear-39          [-1, 28, 28, 192]         147,648\n",
      "        Dropout2d-40          [-1, 28, 28, 192]               0\n",
      "  ConvNeXtBlock2D-41          [-1, 192, 28, 28]               0\n",
      "           Conv2d-42          [-1, 192, 28, 28]           9,600\n",
      "              DyT-43          [-1, 28, 28, 192]               0\n",
      "           Linear-44          [-1, 28, 28, 768]         148,224\n",
      "             GELU-45          [-1, 28, 28, 768]               0\n",
      "           Linear-46          [-1, 28, 28, 192]         147,648\n",
      "        Dropout2d-47          [-1, 28, 28, 192]               0\n",
      "  ConvNeXtBlock2D-48          [-1, 192, 28, 28]               0\n",
      "              DyT-49          [-1, 28, 28, 192]               0\n",
      "      DyT_wrapper-50          [-1, 192, 28, 28]               0\n",
      "           Conv2d-51          [-1, 384, 14, 14]         295,296\n",
      "           Conv2d-52          [-1, 384, 14, 14]          19,200\n",
      "              DyT-53          [-1, 14, 14, 384]               0\n",
      "           Linear-54         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-55         [-1, 14, 14, 1536]               0\n",
      "           Linear-56          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-57          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-58          [-1, 384, 14, 14]               0\n",
      "           Conv2d-59          [-1, 384, 14, 14]          19,200\n",
      "              DyT-60          [-1, 14, 14, 384]               0\n",
      "           Linear-61         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-62         [-1, 14, 14, 1536]               0\n",
      "           Linear-63          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-64          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-65          [-1, 384, 14, 14]               0\n",
      "           Conv2d-66          [-1, 384, 14, 14]          19,200\n",
      "              DyT-67          [-1, 14, 14, 384]               0\n",
      "           Linear-68         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-69         [-1, 14, 14, 1536]               0\n",
      "           Linear-70          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-71          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-72          [-1, 384, 14, 14]               0\n",
      "           Conv2d-73          [-1, 384, 14, 14]          19,200\n",
      "              DyT-74          [-1, 14, 14, 384]               0\n",
      "           Linear-75         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-76         [-1, 14, 14, 1536]               0\n",
      "           Linear-77          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-78          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-79          [-1, 384, 14, 14]               0\n",
      "           Conv2d-80          [-1, 384, 14, 14]          19,200\n",
      "              DyT-81          [-1, 14, 14, 384]               0\n",
      "           Linear-82         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-83         [-1, 14, 14, 1536]               0\n",
      "           Linear-84          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-85          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-86          [-1, 384, 14, 14]               0\n",
      "           Conv2d-87          [-1, 384, 14, 14]          19,200\n",
      "              DyT-88          [-1, 14, 14, 384]               0\n",
      "           Linear-89         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-90         [-1, 14, 14, 1536]               0\n",
      "           Linear-91          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-92          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-93          [-1, 384, 14, 14]               0\n",
      "           Conv2d-94          [-1, 384, 14, 14]          19,200\n",
      "              DyT-95          [-1, 14, 14, 384]               0\n",
      "           Linear-96         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-97         [-1, 14, 14, 1536]               0\n",
      "           Linear-98          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-99          [-1, 14, 14, 384]               0\n",
      " ConvNeXtBlock2D-100          [-1, 384, 14, 14]               0\n",
      "          Conv2d-101          [-1, 384, 14, 14]          19,200\n",
      "             DyT-102          [-1, 14, 14, 384]               0\n",
      "          Linear-103         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-104         [-1, 14, 14, 1536]               0\n",
      "          Linear-105          [-1, 14, 14, 384]         590,208\n",
      "       Dropout2d-106          [-1, 14, 14, 384]               0\n",
      " ConvNeXtBlock2D-107          [-1, 384, 14, 14]               0\n",
      "          Conv2d-108          [-1, 384, 14, 14]          19,200\n",
      "             DyT-109          [-1, 14, 14, 384]               0\n",
      "          Linear-110         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-111         [-1, 14, 14, 1536]               0\n",
      "          Linear-112          [-1, 14, 14, 384]         590,208\n",
      "       Dropout2d-113          [-1, 14, 14, 384]               0\n",
      " ConvNeXtBlock2D-114          [-1, 384, 14, 14]               0\n",
      "             DyT-115          [-1, 14, 14, 384]               0\n",
      "     DyT_wrapper-116          [-1, 384, 14, 14]               0\n",
      "          Conv2d-117            [-1, 768, 7, 7]       1,180,416\n",
      "          Conv2d-118            [-1, 768, 7, 7]          38,400\n",
      "             DyT-119            [-1, 7, 7, 768]               0\n",
      "          Linear-120           [-1, 7, 7, 3072]       2,362,368\n",
      "            GELU-121           [-1, 7, 7, 3072]               0\n",
      "          Linear-122            [-1, 7, 7, 768]       2,360,064\n",
      "       Dropout2d-123            [-1, 7, 7, 768]               0\n",
      " ConvNeXtBlock2D-124            [-1, 768, 7, 7]               0\n",
      "          Conv2d-125            [-1, 768, 7, 7]          38,400\n",
      "             DyT-126            [-1, 7, 7, 768]               0\n",
      "          Linear-127           [-1, 7, 7, 3072]       2,362,368\n",
      "            GELU-128           [-1, 7, 7, 3072]               0\n",
      "          Linear-129            [-1, 7, 7, 768]       2,360,064\n",
      "       Dropout2d-130            [-1, 7, 7, 768]               0\n",
      " ConvNeXtBlock2D-131            [-1, 768, 7, 7]               0\n",
      "          Conv2d-132            [-1, 768, 7, 7]          38,400\n",
      "             DyT-133            [-1, 7, 7, 768]               0\n",
      "          Linear-134           [-1, 7, 7, 3072]       2,362,368\n",
      "            GELU-135           [-1, 7, 7, 3072]               0\n",
      "          Linear-136            [-1, 7, 7, 768]       2,360,064\n",
      "       Dropout2d-137            [-1, 7, 7, 768]               0\n",
      " ConvNeXtBlock2D-138            [-1, 768, 7, 7]               0\n",
      "AdaptiveAvgPool2d-139            [-1, 768, 1, 1]               0\n",
      "         Flatten-140                  [-1, 768]               0\n",
      "             DyT-141                  [-1, 768]               0\n",
      "     DyT_wrapper-142                  [-1, 768]               0\n",
      "================================================================\n",
      "Total params: 27,797,184\n",
      "Trainable params: 27,797,184\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 229.71\n",
      "Params size (MB): 106.04\n",
      "Estimated Total Size (MB): 336.32\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(ConvNext(in_chans=3,dims=[96,192,384,768],stages=[3,3,9,3]), (3,224,224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550dde6d-ca83-4820-a4a1-88cd7b683789",
   "metadata": {},
   "source": [
    "## CSPNet\n",
    "Follows C3K2 block of the YOLOv11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4b4ae994-4700-428b-9d4a-e65f70ea220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Follows Conv class from ultralytics loosely\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        # self.c = nn.Linear(in_channels, out_channels)\n",
    "        self.c = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.movedim(x, 1, -1)\n",
    "        x = self.c(x)\n",
    "        # x = torch.movedim(x, -1, 1)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0d200b0c-fa32-4560-afec-3d5a520026f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 224, 224]              24\n",
      "       BatchNorm2d-2          [-1, 6, 224, 224]              12\n",
      "              SiLU-3          [-1, 6, 224, 224]               0\n",
      "================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 6.89\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 7.46\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "conv = Conv(3, 6)\n",
    "summary(conv, (3,224,224), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b0d50f0b-4c7f-496e-83fb-5a94e82d5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPStage(nn.Module):\n",
    "    def __init__(self, in_channels, num_blocks, **kwargs):\n",
    "        super().__init__()\n",
    "        csp_channels = in_channels * 2\n",
    "        self.base_layer = Conv(in_channels, csp_channels)\n",
    "        self.bottlenecks = nn.ModuleList(\n",
    "            ConvNeXtBlock2D(in_channels, **kwargs) for _ in range(num_blocks)\n",
    "        )\n",
    "        self.transition_layer = Conv((2 + num_blocks) * in_channels, in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_layer(x)\n",
    "        y = list(torch.chunk(x, 2, 1))\n",
    "        y.extend(block(y[-1]) for block in self.bottlenecks)\n",
    "        y = torch.cat(y, 1)\n",
    "        y = self.transition_layer(y)\n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0e0af3a1-740b-440b-af74-7522081ebd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [-1, 192, 224, 224]          18,624\n",
      "       BatchNorm2d-2        [-1, 192, 224, 224]             384\n",
      "              SiLU-3        [-1, 192, 224, 224]               0\n",
      "              Conv-4        [-1, 192, 224, 224]               0\n",
      "            Conv2d-5         [-1, 96, 224, 224]           4,800\n",
      "               DyT-6         [-1, 224, 224, 96]               0\n",
      "            Linear-7        [-1, 224, 224, 384]          37,248\n",
      "              GELU-8        [-1, 224, 224, 384]               0\n",
      "            Linear-9         [-1, 224, 224, 96]          36,960\n",
      "        Dropout2d-10         [-1, 224, 224, 96]               0\n",
      "  ConvNeXtBlock2D-11         [-1, 96, 224, 224]               0\n",
      "           Conv2d-12         [-1, 96, 224, 224]          27,744\n",
      "      BatchNorm2d-13         [-1, 96, 224, 224]             192\n",
      "             SiLU-14         [-1, 96, 224, 224]               0\n",
      "             Conv-15         [-1, 96, 224, 224]               0\n",
      "================================================================\n",
      "Total params: 125,952\n",
      "Trainable params: 125,952\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 18.38\n",
      "Forward/backward pass size (MB): 918.75\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 937.61\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cspStage = CSPStage(96,1)\n",
    "summary(cspStage, (96,224,224), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "41e6d76c-a1ea-4ebf-84a3-e52a4a4e1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPConvNext(nn.Module):\n",
    "    def __init__(self, in_chans=1, dims=[32, 64, 128, 256], stages=[1, 1, 3, 1]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.dims = dims\n",
    "        self.stages = stages\n",
    "\n",
    "        self.downsample_layers = nn.ModuleList()  # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            # myLayerNorm(dims[0], eps=1e-6)\n",
    "            DyT_wrapper(dims[0])\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                # myLayerNorm(dims[i], eps=1e-6),\n",
    "                DyT_wrapper(dims[i]),\n",
    "                nn.Conv2d(dims[i], dims[i + 1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.model_layers = nn.ModuleList()\n",
    "        for i, stage_length in enumerate(stages):\n",
    "            # stage = nn.ModuleList([ConvNeXtBlock2D(dims[i]) for _ in range(stage_length)])\n",
    "            stage = CSPStage(dims[i], stage_length)\n",
    "            self.model_layers.append(stage)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for i in range(len(self.dims)):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.model_layers[i](x)\n",
    "            outputs.append(x)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f5685a6e-98f4-49f9-b139-3188e4136784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 56, 56]             784\n",
      "               DyT-2           [-1, 56, 56, 16]               0\n",
      "       DyT_wrapper-3           [-1, 16, 56, 56]               0\n",
      "            Conv2d-4           [-1, 32, 56, 56]             544\n",
      "       BatchNorm2d-5           [-1, 32, 56, 56]              64\n",
      "              SiLU-6           [-1, 32, 56, 56]               0\n",
      "              Conv-7           [-1, 32, 56, 56]               0\n",
      "            Conv2d-8           [-1, 16, 56, 56]             800\n",
      "               DyT-9           [-1, 56, 56, 16]               0\n",
      "           Linear-10           [-1, 56, 56, 64]           1,088\n",
      "             GELU-11           [-1, 56, 56, 64]               0\n",
      "           Linear-12           [-1, 56, 56, 16]           1,040\n",
      "        Dropout2d-13           [-1, 56, 56, 16]               0\n",
      "  ConvNeXtBlock2D-14           [-1, 16, 56, 56]               0\n",
      "           Conv2d-15           [-1, 16, 56, 56]             800\n",
      "              DyT-16           [-1, 56, 56, 16]               0\n",
      "           Linear-17           [-1, 56, 56, 64]           1,088\n",
      "             GELU-18           [-1, 56, 56, 64]               0\n",
      "           Linear-19           [-1, 56, 56, 16]           1,040\n",
      "        Dropout2d-20           [-1, 56, 56, 16]               0\n",
      "  ConvNeXtBlock2D-21           [-1, 16, 56, 56]               0\n",
      "           Conv2d-22           [-1, 16, 56, 56]           1,040\n",
      "      BatchNorm2d-23           [-1, 16, 56, 56]              32\n",
      "             SiLU-24           [-1, 16, 56, 56]               0\n",
      "             Conv-25           [-1, 16, 56, 56]               0\n",
      "         CSPStage-26           [-1, 16, 56, 56]               0\n",
      "              DyT-27           [-1, 56, 56, 16]               0\n",
      "      DyT_wrapper-28           [-1, 16, 56, 56]               0\n",
      "           Conv2d-29           [-1, 32, 28, 28]           2,080\n",
      "           Conv2d-30           [-1, 64, 28, 28]           2,112\n",
      "      BatchNorm2d-31           [-1, 64, 28, 28]             128\n",
      "             SiLU-32           [-1, 64, 28, 28]               0\n",
      "             Conv-33           [-1, 64, 28, 28]               0\n",
      "           Conv2d-34           [-1, 32, 28, 28]           1,600\n",
      "              DyT-35           [-1, 28, 28, 32]               0\n",
      "           Linear-36          [-1, 28, 28, 128]           4,224\n",
      "             GELU-37          [-1, 28, 28, 128]               0\n",
      "           Linear-38           [-1, 28, 28, 32]           4,128\n",
      "        Dropout2d-39           [-1, 28, 28, 32]               0\n",
      "  ConvNeXtBlock2D-40           [-1, 32, 28, 28]               0\n",
      "           Conv2d-41           [-1, 32, 28, 28]           1,600\n",
      "              DyT-42           [-1, 28, 28, 32]               0\n",
      "           Linear-43          [-1, 28, 28, 128]           4,224\n",
      "             GELU-44          [-1, 28, 28, 128]               0\n",
      "           Linear-45           [-1, 28, 28, 32]           4,128\n",
      "        Dropout2d-46           [-1, 28, 28, 32]               0\n",
      "  ConvNeXtBlock2D-47           [-1, 32, 28, 28]               0\n",
      "           Conv2d-48           [-1, 32, 28, 28]           4,128\n",
      "      BatchNorm2d-49           [-1, 32, 28, 28]              64\n",
      "             SiLU-50           [-1, 32, 28, 28]               0\n",
      "             Conv-51           [-1, 32, 28, 28]               0\n",
      "         CSPStage-52           [-1, 32, 28, 28]               0\n",
      "              DyT-53           [-1, 28, 28, 32]               0\n",
      "      DyT_wrapper-54           [-1, 32, 28, 28]               0\n",
      "           Conv2d-55           [-1, 64, 14, 14]           8,256\n",
      "           Conv2d-56          [-1, 128, 14, 14]           8,320\n",
      "      BatchNorm2d-57          [-1, 128, 14, 14]             256\n",
      "             SiLU-58          [-1, 128, 14, 14]               0\n",
      "             Conv-59          [-1, 128, 14, 14]               0\n",
      "           Conv2d-60           [-1, 64, 14, 14]           3,200\n",
      "              DyT-61           [-1, 14, 14, 64]               0\n",
      "           Linear-62          [-1, 14, 14, 256]          16,640\n",
      "             GELU-63          [-1, 14, 14, 256]               0\n",
      "           Linear-64           [-1, 14, 14, 64]          16,448\n",
      "        Dropout2d-65           [-1, 14, 14, 64]               0\n",
      "  ConvNeXtBlock2D-66           [-1, 64, 14, 14]               0\n",
      "           Conv2d-67           [-1, 64, 14, 14]           3,200\n",
      "              DyT-68           [-1, 14, 14, 64]               0\n",
      "           Linear-69          [-1, 14, 14, 256]          16,640\n",
      "             GELU-70          [-1, 14, 14, 256]               0\n",
      "           Linear-71           [-1, 14, 14, 64]          16,448\n",
      "        Dropout2d-72           [-1, 14, 14, 64]               0\n",
      "  ConvNeXtBlock2D-73           [-1, 64, 14, 14]               0\n",
      "           Conv2d-74           [-1, 64, 14, 14]           3,200\n",
      "              DyT-75           [-1, 14, 14, 64]               0\n",
      "           Linear-76          [-1, 14, 14, 256]          16,640\n",
      "             GELU-77          [-1, 14, 14, 256]               0\n",
      "           Linear-78           [-1, 14, 14, 64]          16,448\n",
      "        Dropout2d-79           [-1, 14, 14, 64]               0\n",
      "  ConvNeXtBlock2D-80           [-1, 64, 14, 14]               0\n",
      "           Conv2d-81           [-1, 64, 14, 14]           3,200\n",
      "              DyT-82           [-1, 14, 14, 64]               0\n",
      "           Linear-83          [-1, 14, 14, 256]          16,640\n",
      "             GELU-84          [-1, 14, 14, 256]               0\n",
      "           Linear-85           [-1, 14, 14, 64]          16,448\n",
      "        Dropout2d-86           [-1, 14, 14, 64]               0\n",
      "  ConvNeXtBlock2D-87           [-1, 64, 14, 14]               0\n",
      "           Conv2d-88           [-1, 64, 14, 14]           3,200\n",
      "              DyT-89           [-1, 14, 14, 64]               0\n",
      "           Linear-90          [-1, 14, 14, 256]          16,640\n",
      "             GELU-91          [-1, 14, 14, 256]               0\n",
      "           Linear-92           [-1, 14, 14, 64]          16,448\n",
      "        Dropout2d-93           [-1, 14, 14, 64]               0\n",
      "  ConvNeXtBlock2D-94           [-1, 64, 14, 14]               0\n",
      "           Conv2d-95           [-1, 64, 14, 14]           3,200\n",
      "              DyT-96           [-1, 14, 14, 64]               0\n",
      "           Linear-97          [-1, 14, 14, 256]          16,640\n",
      "             GELU-98          [-1, 14, 14, 256]               0\n",
      "           Linear-99           [-1, 14, 14, 64]          16,448\n",
      "       Dropout2d-100           [-1, 14, 14, 64]               0\n",
      " ConvNeXtBlock2D-101           [-1, 64, 14, 14]               0\n",
      "          Conv2d-102           [-1, 64, 14, 14]          32,832\n",
      "     BatchNorm2d-103           [-1, 64, 14, 14]             128\n",
      "            SiLU-104           [-1, 64, 14, 14]               0\n",
      "            Conv-105           [-1, 64, 14, 14]               0\n",
      "        CSPStage-106           [-1, 64, 14, 14]               0\n",
      "             DyT-107           [-1, 14, 14, 64]               0\n",
      "     DyT_wrapper-108           [-1, 64, 14, 14]               0\n",
      "          Conv2d-109            [-1, 128, 7, 7]          32,896\n",
      "          Conv2d-110            [-1, 256, 7, 7]          33,024\n",
      "     BatchNorm2d-111            [-1, 256, 7, 7]             512\n",
      "            SiLU-112            [-1, 256, 7, 7]               0\n",
      "            Conv-113            [-1, 256, 7, 7]               0\n",
      "          Conv2d-114            [-1, 128, 7, 7]           6,400\n",
      "             DyT-115            [-1, 7, 7, 128]               0\n",
      "          Linear-116            [-1, 7, 7, 512]          66,048\n",
      "            GELU-117            [-1, 7, 7, 512]               0\n",
      "          Linear-118            [-1, 7, 7, 128]          65,664\n",
      "       Dropout2d-119            [-1, 7, 7, 128]               0\n",
      " ConvNeXtBlock2D-120            [-1, 128, 7, 7]               0\n",
      "          Conv2d-121            [-1, 128, 7, 7]           6,400\n",
      "             DyT-122            [-1, 7, 7, 128]               0\n",
      "          Linear-123            [-1, 7, 7, 512]          66,048\n",
      "            GELU-124            [-1, 7, 7, 512]               0\n",
      "          Linear-125            [-1, 7, 7, 128]          65,664\n",
      "       Dropout2d-126            [-1, 7, 7, 128]               0\n",
      " ConvNeXtBlock2D-127            [-1, 128, 7, 7]               0\n",
      "          Conv2d-128            [-1, 128, 7, 7]          65,664\n",
      "     BatchNorm2d-129            [-1, 128, 7, 7]             256\n",
      "            SiLU-130            [-1, 128, 7, 7]               0\n",
      "            Conv-131            [-1, 128, 7, 7]               0\n",
      "        CSPStage-132            [-1, 128, 7, 7]               0\n",
      "================================================================\n",
      "Total params: 712,832\n",
      "Trainable params: 712,832\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 35.79\n",
      "Params size (MB): 2.72\n",
      "Estimated Total Size (MB): 39.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(CSPConvNext(in_chans=3,dims=[16,32,64,128],stages=[2,2,6,2]), (3,224,224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127a972b-be85-479e-b3ff-14101bd15bdb",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b5c38a01-c523-40ef-8d6a-b719122402b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for 100 iterations: 0.4152 sec\n",
      "Average time per iteration: 4.152 ms\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = CSPConvNext(in_chans=3, dims=[16, 32, 64, 128], stages=[2, 2, 6, 2]).to(device)\n",
    "model.eval()  \n",
    "\n",
    "\n",
    "x = torch.randn(1, 3, 224, 224, device=device)\n",
    "\n",
    "## Warmup\n",
    "for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "        _ = model(x)\n",
    "\n",
    "# Benchmarking 100 iterations\n",
    "torch.cuda.synchronize()\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(100):\n",
    "    with torch.no_grad():\n",
    "        _ = model(x)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "end_time = time.time()\n",
    "\n",
    "# Print results\n",
    "total_time = end_time - start_time\n",
    "avg_time = total_time / 100\n",
    "print(f\"Total time for 100 iterations: {total_time:.4f} sec\")\n",
    "print(f\"Average time per iteration: {avg_time * 1000:.3f} ms\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05359a0b-9da8-434d-a897-b47c63053258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
