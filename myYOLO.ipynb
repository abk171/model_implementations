{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2060fe75-35c8-4d72-add5-7637fee999ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f9184-b880-4c83-bb31-a75e8796ee16",
   "metadata": {},
   "source": [
    "## Dynamic Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bd8ba601-143d-4ff5-97c5-7f9560c926ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DyT(nn.Module):\n",
    "    def __init__(self, dims, init_alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.ones(1) * init_alpha)\n",
    "        self.gamma = nn.Parameter(torch.ones(dims))\n",
    "        self.beta = nn.Parameter(torch.zeros(dims))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gamma * torch.tanh(self.alpha * x) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "315f18cc-6189-445e-9323-dab6022ab684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DyT_wrapper(nn.Module):\n",
    "    def __init__(self, dims, init_alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.dyt = DyT(dims, init_alpha)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.movedim(x, 1,-1)\n",
    "        x = self.dyt(x)\n",
    "        x = torch.movedim(x, -1, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed157e6-c520-4cd5-a135-51c55ee4bc26",
   "metadata": {},
   "source": [
    "## ConvNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fb2ac4b4-5355-4fc1-8c63-7f2596df8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXtBlock2D(nn.Module):\n",
    "  def __init__(self, dim, layer_scale_init_value=1e-6, drop=0.2, **kwargs):\n",
    "    super().__init__()\n",
    "\n",
    "    self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)  # depthwise conv\n",
    "\n",
    "    # self.norm = nn.LayerNorm(dim)\n",
    "    self.norm = DyT(dim)\n",
    "\n",
    "    self.pwconv1 = nn.Linear(dim, 4 * dim)\n",
    "    self.act = nn.GELU()\n",
    "    self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "\n",
    "    self.dropout = nn.Dropout2d(p=drop)\n",
    "\n",
    "    self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim,)), requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    residual = x\n",
    "    x = self.dwconv(x)\n",
    "\n",
    "    # Transpose for LayerNorm\n",
    "    x = x.permute(0, 2, 3, 1)\n",
    "    x = self.norm(x)\n",
    "\n",
    "    x = self.pwconv1(x)\n",
    "    x = self.act(x)\n",
    "    x = self.pwconv2(x)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    if self.gamma is not None:\n",
    "        x = self.gamma * x\n",
    "\n",
    "    # Transpose back to (B, C, H, W)\n",
    "    x = x.permute(0, 3, 1, 2)\n",
    "    # no drop path y\n",
    "    return residual + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2365b568-9d03-486d-8ed0-1861e24e1380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 112, 112]           4,800\n",
      "               DyT-2         [-1, 112, 112, 96]               0\n",
      "            Linear-3        [-1, 112, 112, 384]          37,248\n",
      "              GELU-4        [-1, 112, 112, 384]               0\n",
      "            Linear-5         [-1, 112, 112, 96]          36,960\n",
      "         Dropout2d-6         [-1, 112, 112, 96]               0\n",
      "================================================================\n",
      "Total params: 79,008\n",
      "Trainable params: 79,008\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.59\n",
      "Forward/backward pass size (MB): 110.25\n",
      "Params size (MB): 0.30\n",
      "Estimated Total Size (MB): 115.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "block = ConvNeXtBlock2D(96)\n",
    "summary(block, (96,112,112), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b224cc37-6061-4473-acf4-46c742937b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNext(nn.Module):\n",
    "    def __init__(self, in_chans=1, dims=[32, 64, 128, 256], stages=[1, 1, 3, 1]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.dims = dims\n",
    "        self.stages = stages\n",
    "\n",
    "        self.downsample_layers = nn.ModuleList()  # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            # myLayerNorm(dims[0], eps=1e-6)\n",
    "            DyT_wrapper(dims[0])\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                # myLayerNorm(dims[i], eps=1e-6),\n",
    "                DyT_wrapper(dims[i]),\n",
    "                nn.Conv2d(dims[i], dims[i + 1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.model_layers = nn.ModuleList()\n",
    "        for i, stage_length in enumerate(stages):\n",
    "            stage = nn.ModuleList([ConvNeXtBlock2D(dims[i]) for _ in range(stage_length)])\n",
    "            self.model_layers.append(stage)\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        # self.final_norm = nn.LayerNorm(dims[-1])\n",
    "        self.final_norm = DyT_wrapper(dims[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.dims)):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            for layer in self.model_layers[i]:\n",
    "                x = layer(x)\n",
    "\n",
    "        x = self.pooling(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.final_norm(x)  # Final normalization\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "25e81761-8eb8-411e-8ce4-54fe4abeea0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 56, 56]           4,704\n",
      "               DyT-2           [-1, 56, 56, 96]               0\n",
      "       DyT_wrapper-3           [-1, 96, 56, 56]               0\n",
      "            Conv2d-4           [-1, 96, 56, 56]           4,800\n",
      "               DyT-5           [-1, 56, 56, 96]               0\n",
      "            Linear-6          [-1, 56, 56, 384]          37,248\n",
      "              GELU-7          [-1, 56, 56, 384]               0\n",
      "            Linear-8           [-1, 56, 56, 96]          36,960\n",
      "         Dropout2d-9           [-1, 56, 56, 96]               0\n",
      "  ConvNeXtBlock2D-10           [-1, 96, 56, 56]               0\n",
      "           Conv2d-11           [-1, 96, 56, 56]           4,800\n",
      "              DyT-12           [-1, 56, 56, 96]               0\n",
      "           Linear-13          [-1, 56, 56, 384]          37,248\n",
      "             GELU-14          [-1, 56, 56, 384]               0\n",
      "           Linear-15           [-1, 56, 56, 96]          36,960\n",
      "        Dropout2d-16           [-1, 56, 56, 96]               0\n",
      "  ConvNeXtBlock2D-17           [-1, 96, 56, 56]               0\n",
      "           Conv2d-18           [-1, 96, 56, 56]           4,800\n",
      "              DyT-19           [-1, 56, 56, 96]               0\n",
      "           Linear-20          [-1, 56, 56, 384]          37,248\n",
      "             GELU-21          [-1, 56, 56, 384]               0\n",
      "           Linear-22           [-1, 56, 56, 96]          36,960\n",
      "        Dropout2d-23           [-1, 56, 56, 96]               0\n",
      "  ConvNeXtBlock2D-24           [-1, 96, 56, 56]               0\n",
      "              DyT-25           [-1, 56, 56, 96]               0\n",
      "      DyT_wrapper-26           [-1, 96, 56, 56]               0\n",
      "           Conv2d-27          [-1, 192, 28, 28]          73,920\n",
      "           Conv2d-28          [-1, 192, 28, 28]           9,600\n",
      "              DyT-29          [-1, 28, 28, 192]               0\n",
      "           Linear-30          [-1, 28, 28, 768]         148,224\n",
      "             GELU-31          [-1, 28, 28, 768]               0\n",
      "           Linear-32          [-1, 28, 28, 192]         147,648\n",
      "        Dropout2d-33          [-1, 28, 28, 192]               0\n",
      "  ConvNeXtBlock2D-34          [-1, 192, 28, 28]               0\n",
      "           Conv2d-35          [-1, 192, 28, 28]           9,600\n",
      "              DyT-36          [-1, 28, 28, 192]               0\n",
      "           Linear-37          [-1, 28, 28, 768]         148,224\n",
      "             GELU-38          [-1, 28, 28, 768]               0\n",
      "           Linear-39          [-1, 28, 28, 192]         147,648\n",
      "        Dropout2d-40          [-1, 28, 28, 192]               0\n",
      "  ConvNeXtBlock2D-41          [-1, 192, 28, 28]               0\n",
      "           Conv2d-42          [-1, 192, 28, 28]           9,600\n",
      "              DyT-43          [-1, 28, 28, 192]               0\n",
      "           Linear-44          [-1, 28, 28, 768]         148,224\n",
      "             GELU-45          [-1, 28, 28, 768]               0\n",
      "           Linear-46          [-1, 28, 28, 192]         147,648\n",
      "        Dropout2d-47          [-1, 28, 28, 192]               0\n",
      "  ConvNeXtBlock2D-48          [-1, 192, 28, 28]               0\n",
      "              DyT-49          [-1, 28, 28, 192]               0\n",
      "      DyT_wrapper-50          [-1, 192, 28, 28]               0\n",
      "           Conv2d-51          [-1, 384, 14, 14]         295,296\n",
      "           Conv2d-52          [-1, 384, 14, 14]          19,200\n",
      "              DyT-53          [-1, 14, 14, 384]               0\n",
      "           Linear-54         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-55         [-1, 14, 14, 1536]               0\n",
      "           Linear-56          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-57          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-58          [-1, 384, 14, 14]               0\n",
      "           Conv2d-59          [-1, 384, 14, 14]          19,200\n",
      "              DyT-60          [-1, 14, 14, 384]               0\n",
      "           Linear-61         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-62         [-1, 14, 14, 1536]               0\n",
      "           Linear-63          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-64          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-65          [-1, 384, 14, 14]               0\n",
      "           Conv2d-66          [-1, 384, 14, 14]          19,200\n",
      "              DyT-67          [-1, 14, 14, 384]               0\n",
      "           Linear-68         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-69         [-1, 14, 14, 1536]               0\n",
      "           Linear-70          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-71          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-72          [-1, 384, 14, 14]               0\n",
      "           Conv2d-73          [-1, 384, 14, 14]          19,200\n",
      "              DyT-74          [-1, 14, 14, 384]               0\n",
      "           Linear-75         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-76         [-1, 14, 14, 1536]               0\n",
      "           Linear-77          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-78          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-79          [-1, 384, 14, 14]               0\n",
      "           Conv2d-80          [-1, 384, 14, 14]          19,200\n",
      "              DyT-81          [-1, 14, 14, 384]               0\n",
      "           Linear-82         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-83         [-1, 14, 14, 1536]               0\n",
      "           Linear-84          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-85          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-86          [-1, 384, 14, 14]               0\n",
      "           Conv2d-87          [-1, 384, 14, 14]          19,200\n",
      "              DyT-88          [-1, 14, 14, 384]               0\n",
      "           Linear-89         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-90         [-1, 14, 14, 1536]               0\n",
      "           Linear-91          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-92          [-1, 14, 14, 384]               0\n",
      "  ConvNeXtBlock2D-93          [-1, 384, 14, 14]               0\n",
      "           Conv2d-94          [-1, 384, 14, 14]          19,200\n",
      "              DyT-95          [-1, 14, 14, 384]               0\n",
      "           Linear-96         [-1, 14, 14, 1536]         591,360\n",
      "             GELU-97         [-1, 14, 14, 1536]               0\n",
      "           Linear-98          [-1, 14, 14, 384]         590,208\n",
      "        Dropout2d-99          [-1, 14, 14, 384]               0\n",
      " ConvNeXtBlock2D-100          [-1, 384, 14, 14]               0\n",
      "          Conv2d-101          [-1, 384, 14, 14]          19,200\n",
      "             DyT-102          [-1, 14, 14, 384]               0\n",
      "          Linear-103         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-104         [-1, 14, 14, 1536]               0\n",
      "          Linear-105          [-1, 14, 14, 384]         590,208\n",
      "       Dropout2d-106          [-1, 14, 14, 384]               0\n",
      " ConvNeXtBlock2D-107          [-1, 384, 14, 14]               0\n",
      "          Conv2d-108          [-1, 384, 14, 14]          19,200\n",
      "             DyT-109          [-1, 14, 14, 384]               0\n",
      "          Linear-110         [-1, 14, 14, 1536]         591,360\n",
      "            GELU-111         [-1, 14, 14, 1536]               0\n",
      "          Linear-112          [-1, 14, 14, 384]         590,208\n",
      "       Dropout2d-113          [-1, 14, 14, 384]               0\n",
      " ConvNeXtBlock2D-114          [-1, 384, 14, 14]               0\n",
      "             DyT-115          [-1, 14, 14, 384]               0\n",
      "     DyT_wrapper-116          [-1, 384, 14, 14]               0\n",
      "          Conv2d-117            [-1, 768, 7, 7]       1,180,416\n",
      "          Conv2d-118            [-1, 768, 7, 7]          38,400\n",
      "             DyT-119            [-1, 7, 7, 768]               0\n",
      "          Linear-120           [-1, 7, 7, 3072]       2,362,368\n",
      "            GELU-121           [-1, 7, 7, 3072]               0\n",
      "          Linear-122            [-1, 7, 7, 768]       2,360,064\n",
      "       Dropout2d-123            [-1, 7, 7, 768]               0\n",
      " ConvNeXtBlock2D-124            [-1, 768, 7, 7]               0\n",
      "          Conv2d-125            [-1, 768, 7, 7]          38,400\n",
      "             DyT-126            [-1, 7, 7, 768]               0\n",
      "          Linear-127           [-1, 7, 7, 3072]       2,362,368\n",
      "            GELU-128           [-1, 7, 7, 3072]               0\n",
      "          Linear-129            [-1, 7, 7, 768]       2,360,064\n",
      "       Dropout2d-130            [-1, 7, 7, 768]               0\n",
      " ConvNeXtBlock2D-131            [-1, 768, 7, 7]               0\n",
      "          Conv2d-132            [-1, 768, 7, 7]          38,400\n",
      "             DyT-133            [-1, 7, 7, 768]               0\n",
      "          Linear-134           [-1, 7, 7, 3072]       2,362,368\n",
      "            GELU-135           [-1, 7, 7, 3072]               0\n",
      "          Linear-136            [-1, 7, 7, 768]       2,360,064\n",
      "       Dropout2d-137            [-1, 7, 7, 768]               0\n",
      " ConvNeXtBlock2D-138            [-1, 768, 7, 7]               0\n",
      "AdaptiveAvgPool2d-139            [-1, 768, 1, 1]               0\n",
      "         Flatten-140                  [-1, 768]               0\n",
      "             DyT-141                  [-1, 768]               0\n",
      "     DyT_wrapper-142                  [-1, 768]               0\n",
      "================================================================\n",
      "Total params: 27,797,184\n",
      "Trainable params: 27,797,184\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 229.71\n",
      "Params size (MB): 106.04\n",
      "Estimated Total Size (MB): 336.32\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(ConvNext(in_chans=3,dims=[96,192,384,768],stages=[3,3,9,3]), (3,224,224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550dde6d-ca83-4820-a4a1-88cd7b683789",
   "metadata": {},
   "source": [
    "## CSPNet\n",
    "Follows C2F block from YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4b4ae994-4700-428b-9d4a-e65f70ea220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Follows Conv class from ultralytics loosely\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        # self.c = nn.Linear(in_channels, out_channels)\n",
    "        self.c = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.movedim(x, 1, -1)\n",
    "        x = self.c(x)\n",
    "        # x = torch.movedim(x, -1, 1)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0d200b0c-fa32-4560-afec-3d5a520026f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 224, 224]              24\n",
      "       BatchNorm2d-2          [-1, 6, 224, 224]              12\n",
      "              SiLU-3          [-1, 6, 224, 224]               0\n",
      "================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 6.89\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 7.46\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "conv = Conv(3, 6)\n",
    "summary(conv, (3,224,224), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b0d50f0b-4c7f-496e-83fb-5a94e82d5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPStage(nn.Module):\n",
    "    def __init__(self, in_channels, num_blocks, **kwargs):\n",
    "        super().__init__()\n",
    "        csp_channels = in_channels * 2\n",
    "        self.base_layer = Conv(in_channels, csp_channels)\n",
    "        self.bottlenecks = nn.ModuleList(\n",
    "            ConvNeXtBlock2D(in_channels, **kwargs) for _ in range(num_blocks)\n",
    "        )\n",
    "        self.transition_layer = Conv((2 + num_blocks) * in_channels, in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_layer(x)\n",
    "        y = list(torch.chunk(x, 2, 1))\n",
    "        y.extend(block(y[-1]) for block in self.bottlenecks)\n",
    "        y = torch.cat(y, 1)\n",
    "        y = self.transition_layer(y)\n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0e0af3a1-740b-440b-af74-7522081ebd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [-1, 192, 224, 224]          18,624\n",
      "       BatchNorm2d-2        [-1, 192, 224, 224]             384\n",
      "              SiLU-3        [-1, 192, 224, 224]               0\n",
      "              Conv-4        [-1, 192, 224, 224]               0\n",
      "            Conv2d-5         [-1, 96, 224, 224]           4,800\n",
      "               DyT-6         [-1, 224, 224, 96]               0\n",
      "            Linear-7        [-1, 224, 224, 384]          37,248\n",
      "              GELU-8        [-1, 224, 224, 384]               0\n",
      "            Linear-9         [-1, 224, 224, 96]          36,960\n",
      "        Dropout2d-10         [-1, 224, 224, 96]               0\n",
      "  ConvNeXtBlock2D-11         [-1, 96, 224, 224]               0\n",
      "           Conv2d-12         [-1, 96, 224, 224]          27,744\n",
      "      BatchNorm2d-13         [-1, 96, 224, 224]             192\n",
      "             SiLU-14         [-1, 96, 224, 224]               0\n",
      "             Conv-15         [-1, 96, 224, 224]               0\n",
      "================================================================\n",
      "Total params: 125,952\n",
      "Trainable params: 125,952\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 18.38\n",
      "Forward/backward pass size (MB): 918.75\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 937.61\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cspStage = CSPStage(96,1)\n",
    "summary(cspStage, (96,224,224), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "41e6d76c-a1ea-4ebf-84a3-e52a4a4e1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPConvNext(nn.Module):\n",
    "    def __init__(self, in_chans=1, dims=[32, 64, 128, 256], stages=[1, 1, 3, 1]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.dims = dims\n",
    "        self.stages = stages\n",
    "\n",
    "        self.downsample_layers = nn.ModuleList()  # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n",
    "            # myLayerNorm(dims[0], eps=1e-6)\n",
    "            DyT_wrapper(dims[0])\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                # myLayerNorm(dims[i], eps=1e-6),\n",
    "                DyT_wrapper(dims[i]),\n",
    "                nn.Conv2d(dims[i], dims[i + 1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.model_layers = nn.ModuleList()\n",
    "        for i, stage_length in enumerate(stages):\n",
    "            # stage = nn.ModuleList([ConvNeXtBlock2D(dims[i]) for _ in range(stage_length)])\n",
    "            stage = CSPStage(dims[i], stage_length)\n",
    "            self.model_layers.append(stage)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for i in range(len(self.dims)):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.model_layers[i](x)\n",
    "            outputs.append(x)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f5685a6e-98f4-49f9-b139-3188e4136784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 160, 160]             784\n",
      "               DyT-2         [-1, 160, 160, 16]               0\n",
      "       DyT_wrapper-3         [-1, 16, 160, 160]               0\n",
      "            Conv2d-4         [-1, 32, 160, 160]             544\n",
      "       BatchNorm2d-5         [-1, 32, 160, 160]              64\n",
      "              SiLU-6         [-1, 32, 160, 160]               0\n",
      "              Conv-7         [-1, 32, 160, 160]               0\n",
      "            Conv2d-8         [-1, 16, 160, 160]             800\n",
      "               DyT-9         [-1, 160, 160, 16]               0\n",
      "           Linear-10         [-1, 160, 160, 64]           1,088\n",
      "             GELU-11         [-1, 160, 160, 64]               0\n",
      "           Linear-12         [-1, 160, 160, 16]           1,040\n",
      "        Dropout2d-13         [-1, 160, 160, 16]               0\n",
      "  ConvNeXtBlock2D-14         [-1, 16, 160, 160]               0\n",
      "           Conv2d-15         [-1, 16, 160, 160]             800\n",
      "              DyT-16         [-1, 160, 160, 16]               0\n",
      "           Linear-17         [-1, 160, 160, 64]           1,088\n",
      "             GELU-18         [-1, 160, 160, 64]               0\n",
      "           Linear-19         [-1, 160, 160, 16]           1,040\n",
      "        Dropout2d-20         [-1, 160, 160, 16]               0\n",
      "  ConvNeXtBlock2D-21         [-1, 16, 160, 160]               0\n",
      "           Conv2d-22         [-1, 16, 160, 160]           1,040\n",
      "      BatchNorm2d-23         [-1, 16, 160, 160]              32\n",
      "             SiLU-24         [-1, 16, 160, 160]               0\n",
      "             Conv-25         [-1, 16, 160, 160]               0\n",
      "         CSPStage-26         [-1, 16, 160, 160]               0\n",
      "              DyT-27         [-1, 160, 160, 16]               0\n",
      "      DyT_wrapper-28         [-1, 16, 160, 160]               0\n",
      "           Conv2d-29           [-1, 32, 80, 80]           2,080\n",
      "           Conv2d-30           [-1, 64, 80, 80]           2,112\n",
      "      BatchNorm2d-31           [-1, 64, 80, 80]             128\n",
      "             SiLU-32           [-1, 64, 80, 80]               0\n",
      "             Conv-33           [-1, 64, 80, 80]               0\n",
      "           Conv2d-34           [-1, 32, 80, 80]           1,600\n",
      "              DyT-35           [-1, 80, 80, 32]               0\n",
      "           Linear-36          [-1, 80, 80, 128]           4,224\n",
      "             GELU-37          [-1, 80, 80, 128]               0\n",
      "           Linear-38           [-1, 80, 80, 32]           4,128\n",
      "        Dropout2d-39           [-1, 80, 80, 32]               0\n",
      "  ConvNeXtBlock2D-40           [-1, 32, 80, 80]               0\n",
      "           Conv2d-41           [-1, 32, 80, 80]           1,600\n",
      "              DyT-42           [-1, 80, 80, 32]               0\n",
      "           Linear-43          [-1, 80, 80, 128]           4,224\n",
      "             GELU-44          [-1, 80, 80, 128]               0\n",
      "           Linear-45           [-1, 80, 80, 32]           4,128\n",
      "        Dropout2d-46           [-1, 80, 80, 32]               0\n",
      "  ConvNeXtBlock2D-47           [-1, 32, 80, 80]               0\n",
      "           Conv2d-48           [-1, 32, 80, 80]           4,128\n",
      "      BatchNorm2d-49           [-1, 32, 80, 80]              64\n",
      "             SiLU-50           [-1, 32, 80, 80]               0\n",
      "             Conv-51           [-1, 32, 80, 80]               0\n",
      "         CSPStage-52           [-1, 32, 80, 80]               0\n",
      "              DyT-53           [-1, 80, 80, 32]               0\n",
      "      DyT_wrapper-54           [-1, 32, 80, 80]               0\n",
      "           Conv2d-55           [-1, 64, 40, 40]           8,256\n",
      "           Conv2d-56          [-1, 128, 40, 40]           8,320\n",
      "      BatchNorm2d-57          [-1, 128, 40, 40]             256\n",
      "             SiLU-58          [-1, 128, 40, 40]               0\n",
      "             Conv-59          [-1, 128, 40, 40]               0\n",
      "           Conv2d-60           [-1, 64, 40, 40]           3,200\n",
      "              DyT-61           [-1, 40, 40, 64]               0\n",
      "           Linear-62          [-1, 40, 40, 256]          16,640\n",
      "             GELU-63          [-1, 40, 40, 256]               0\n",
      "           Linear-64           [-1, 40, 40, 64]          16,448\n",
      "        Dropout2d-65           [-1, 40, 40, 64]               0\n",
      "  ConvNeXtBlock2D-66           [-1, 64, 40, 40]               0\n",
      "           Conv2d-67           [-1, 64, 40, 40]           3,200\n",
      "              DyT-68           [-1, 40, 40, 64]               0\n",
      "           Linear-69          [-1, 40, 40, 256]          16,640\n",
      "             GELU-70          [-1, 40, 40, 256]               0\n",
      "           Linear-71           [-1, 40, 40, 64]          16,448\n",
      "        Dropout2d-72           [-1, 40, 40, 64]               0\n",
      "  ConvNeXtBlock2D-73           [-1, 64, 40, 40]               0\n",
      "           Conv2d-74           [-1, 64, 40, 40]           3,200\n",
      "              DyT-75           [-1, 40, 40, 64]               0\n",
      "           Linear-76          [-1, 40, 40, 256]          16,640\n",
      "             GELU-77          [-1, 40, 40, 256]               0\n",
      "           Linear-78           [-1, 40, 40, 64]          16,448\n",
      "        Dropout2d-79           [-1, 40, 40, 64]               0\n",
      "  ConvNeXtBlock2D-80           [-1, 64, 40, 40]               0\n",
      "           Conv2d-81           [-1, 64, 40, 40]           3,200\n",
      "              DyT-82           [-1, 40, 40, 64]               0\n",
      "           Linear-83          [-1, 40, 40, 256]          16,640\n",
      "             GELU-84          [-1, 40, 40, 256]               0\n",
      "           Linear-85           [-1, 40, 40, 64]          16,448\n",
      "        Dropout2d-86           [-1, 40, 40, 64]               0\n",
      "  ConvNeXtBlock2D-87           [-1, 64, 40, 40]               0\n",
      "           Conv2d-88           [-1, 64, 40, 40]           3,200\n",
      "              DyT-89           [-1, 40, 40, 64]               0\n",
      "           Linear-90          [-1, 40, 40, 256]          16,640\n",
      "             GELU-91          [-1, 40, 40, 256]               0\n",
      "           Linear-92           [-1, 40, 40, 64]          16,448\n",
      "        Dropout2d-93           [-1, 40, 40, 64]               0\n",
      "  ConvNeXtBlock2D-94           [-1, 64, 40, 40]               0\n",
      "           Conv2d-95           [-1, 64, 40, 40]           3,200\n",
      "              DyT-96           [-1, 40, 40, 64]               0\n",
      "           Linear-97          [-1, 40, 40, 256]          16,640\n",
      "             GELU-98          [-1, 40, 40, 256]               0\n",
      "           Linear-99           [-1, 40, 40, 64]          16,448\n",
      "       Dropout2d-100           [-1, 40, 40, 64]               0\n",
      " ConvNeXtBlock2D-101           [-1, 64, 40, 40]               0\n",
      "          Conv2d-102           [-1, 64, 40, 40]          32,832\n",
      "     BatchNorm2d-103           [-1, 64, 40, 40]             128\n",
      "            SiLU-104           [-1, 64, 40, 40]               0\n",
      "            Conv-105           [-1, 64, 40, 40]               0\n",
      "        CSPStage-106           [-1, 64, 40, 40]               0\n",
      "             DyT-107           [-1, 40, 40, 64]               0\n",
      "     DyT_wrapper-108           [-1, 64, 40, 40]               0\n",
      "          Conv2d-109          [-1, 128, 20, 20]          32,896\n",
      "          Conv2d-110          [-1, 256, 20, 20]          33,024\n",
      "     BatchNorm2d-111          [-1, 256, 20, 20]             512\n",
      "            SiLU-112          [-1, 256, 20, 20]               0\n",
      "            Conv-113          [-1, 256, 20, 20]               0\n",
      "          Conv2d-114          [-1, 128, 20, 20]           6,400\n",
      "             DyT-115          [-1, 20, 20, 128]               0\n",
      "          Linear-116          [-1, 20, 20, 512]          66,048\n",
      "            GELU-117          [-1, 20, 20, 512]               0\n",
      "          Linear-118          [-1, 20, 20, 128]          65,664\n",
      "       Dropout2d-119          [-1, 20, 20, 128]               0\n",
      " ConvNeXtBlock2D-120          [-1, 128, 20, 20]               0\n",
      "          Conv2d-121          [-1, 128, 20, 20]           6,400\n",
      "             DyT-122          [-1, 20, 20, 128]               0\n",
      "          Linear-123          [-1, 20, 20, 512]          66,048\n",
      "            GELU-124          [-1, 20, 20, 512]               0\n",
      "          Linear-125          [-1, 20, 20, 128]          65,664\n",
      "       Dropout2d-126          [-1, 20, 20, 128]               0\n",
      " ConvNeXtBlock2D-127          [-1, 128, 20, 20]               0\n",
      "          Conv2d-128          [-1, 128, 20, 20]          65,664\n",
      "     BatchNorm2d-129          [-1, 128, 20, 20]             256\n",
      "            SiLU-130          [-1, 128, 20, 20]               0\n",
      "            Conv-131          [-1, 128, 20, 20]               0\n",
      "        CSPStage-132          [-1, 128, 20, 20]               0\n",
      "================================================================\n",
      "Total params: 712,832\n",
      "Trainable params: 712,832\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.69\n",
      "Forward/backward pass size (MB): 292.19\n",
      "Params size (MB): 2.72\n",
      "Estimated Total Size (MB): 299.59\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(CSPConvNext(in_chans=3,dims=[16,32,64,128],stages=[2,2,6,2]).to(device), (3,640,640))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4822bcad-ffd9-45dd-92b4-a7aa35b6c84c",
   "metadata": {},
   "source": [
    "## I modified Ultralytics instead\n",
    "Building the rest is a headache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be643ec-8ab1-4aca-a7a0-8467b9a0ec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('/home/abk171/ultralytics')\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109b6def-2f27-47ce-89cb-7b0a2b97bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.nn.modules.block import C3k2NeXt, C2f, DyT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7866e92c-df90-47a1-8fe9-d62f1dea8eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 224, 224]             256\n",
      "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
      "              SiLU-3         [-1, 16, 224, 224]               0\n",
      "              SiLU-4         [-1, 16, 224, 224]               0\n",
      "              Conv-5         [-1, 16, 224, 224]               0\n",
      "            Conv2d-6          [-1, 8, 224, 224]             400\n",
      "               DyT-7          [-1, 224, 224, 8]               0\n",
      "            Linear-8         [-1, 224, 224, 32]             288\n",
      "              GELU-9         [-1, 224, 224, 32]               0\n",
      "           Linear-10          [-1, 224, 224, 8]             264\n",
      "        Dropout2d-11          [-1, 224, 224, 8]               0\n",
      "ConvNeXtBottleNeck-12          [-1, 8, 224, 224]               0\n",
      "           Conv2d-13          [-1, 8, 224, 224]             400\n",
      "              DyT-14          [-1, 224, 224, 8]               0\n",
      "           Linear-15         [-1, 224, 224, 32]             288\n",
      "             GELU-16         [-1, 224, 224, 32]               0\n",
      "           Linear-17          [-1, 224, 224, 8]             264\n",
      "        Dropout2d-18          [-1, 224, 224, 8]               0\n",
      "ConvNeXtBottleNeck-19          [-1, 8, 224, 224]               0\n",
      "           Conv2d-20          [-1, 8, 224, 224]             400\n",
      "              DyT-21          [-1, 224, 224, 8]               0\n",
      "           Linear-22         [-1, 224, 224, 32]             288\n",
      "             GELU-23         [-1, 224, 224, 32]               0\n",
      "           Linear-24          [-1, 224, 224, 8]             264\n",
      "        Dropout2d-25          [-1, 224, 224, 8]               0\n",
      "ConvNeXtBottleNeck-26          [-1, 8, 224, 224]               0\n",
      "           Conv2d-27         [-1, 16, 224, 224]             640\n",
      "      BatchNorm2d-28         [-1, 16, 224, 224]              32\n",
      "             SiLU-29         [-1, 16, 224, 224]               0\n",
      "             SiLU-30         [-1, 16, 224, 224]               0\n",
      "             Conv-31         [-1, 16, 224, 224]               0\n",
      "================================================================\n",
      "Total params: 3,816\n",
      "Trainable params: 3,816\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.06\n",
      "Forward/backward pass size (MB): 180.69\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 183.76\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(C3k2NeXt(16,16,n=3).to('cuda'), (16,224,224), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de9bc373-9597-4d11-8584-8d760e508e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C3k2NeXt(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): ConvNeXtBottleNeck(\n",
       "            (dwconv): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=16)\n",
       "            (norm): DyT()\n",
       "            (pwconv1): Linear(in_features=16, out_features=64, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=64, out_features=16, bias=True)\n",
       "            (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C3k2NeXt(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): ConvNeXtBottleNeck(\n",
       "            (dwconv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\n",
       "            (norm): DyT()\n",
       "            (pwconv1): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C3k2NeXt(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C3k2NeXt(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): C2PSA(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): Sequential(\n",
       "          (0): PSABlock(\n",
       "            (attn): Attention(\n",
       "              (qkv): Conv(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (proj): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (pe): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (ffn): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (12): Concat()\n",
       "      (13): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (15): Concat()\n",
       "      (16): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (18): Concat()\n",
       "      (19): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (21): Concat()\n",
       "      (22): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YOLO(\"yolo11-next.yaml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
